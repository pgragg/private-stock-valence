{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = 'features_by_valence/'\n",
    "label_set = ['low', 'high']\n",
    "low_files = glob.glob(root_path + label_set[0] + '/*')\n",
    "high_files = glob.glob(root_path + label_set[1] + '/*')\n",
    "\n",
    "features = {'low':[], 'high':[]}\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for filename in low_files:\n",
    "    word_histogram = json.loads(open(filename).read())\n",
    "    features['low'].append(word_histogram)\n",
    "    all_features.append({'dictionary': word_histogram, 'label': 'low'})\n",
    "for filename in high_files:\n",
    "    word_histogram = json.loads(open(filename).read())\n",
    "    features['high'].append(word_histogram)\n",
    "    all_features.append({'dictionary': word_histogram, 'label': 'high'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 252\n",
      "train: 201\n",
      "test: 50\n"
     ]
    }
   ],
   "source": [
    "n_total = int(len(all_features))\n",
    "n_train = int(n_total * 0.8)\n",
    "n_test = int(n_total * 0.2)\n",
    "\n",
    "print('total: ' + str(n_total))\n",
    "print('train: ' + str(n_train))\n",
    "print('test: ' + str(n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 109, 'low': 143}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = {}\n",
    "label_counts['high'] = len(features['high'])\n",
    "label_counts['low'] = len(features['low'])\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 1, 'low': 0}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding\n",
    "ohe = {}\n",
    "i_2_label = {}\n",
    "i_2_label[0] = 'low'\n",
    "i_2_label[1] = 'high'\n",
    "ohe['high'] = 1\n",
    "ohe['low'] = 0\n",
    "\n",
    "ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_word_embeddings(af):\n",
    "    wes = {}\n",
    "    for d_a_l_o in af:\n",
    "        dictionary = d_a_l_o['dictionary']\n",
    "        label = d_a_l_o['label']\n",
    "        for word in dictionary:\n",
    "            word_count_in_document = dictionary[word]\n",
    "            wes[word] = wes.get(word, np.zeros(len(ohe)))\n",
    "            pos = ohe[label]\n",
    "            wes[word][pos] = wes[word][pos] + (float(word_count_in_document)/float(label_counts[label]))\n",
    "    return wes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dictionary, wes, label_counts):\n",
    "    outcome = np.zeros(len(ohe))\n",
    "    for word in dictionary:\n",
    "        word_count_in_document = dictionary[word]\n",
    "        lookup = wes.get( word, np.zeros(len(ohe)) )\n",
    "        norm_lookup = float(np.linalg.norm(lookup))\n",
    "        for i, n in enumerate(lookup):\n",
    "            label_count = label_counts[i_2_label[int(i)]]\n",
    "            outcome[i] = outcome[i] + (n*word_count_in_document)/(norm_lookup*norm_lookup)\n",
    "    pi = np.argmax(outcome)\n",
    "    oi = np.argmin(outcome)\n",
    "    label = i_2_label[pi]\n",
    "    score = (float(outcome[pi])/float(outcome[oi]))\n",
    "    if score < 2.1:\n",
    "        label = 'high'\n",
    "    else:\n",
    "        label = 'low'\n",
    "    return [label, score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.66914953962\n",
      "2.26330473542\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for fd in features['high']:\n",
    "    c, score = classify(fd, wes, label_counts)\n",
    "#     print(c)\n",
    "    scores.append(score)\n",
    "print(np.average(scores))\n",
    "\n",
    "scores = []\n",
    "for fd in features['low']:\n",
    "    c, score = classify(fd, wes, label_counts)\n",
    "#     print(c)\n",
    "    scores.append(score)\n",
    "print(np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_surety = []\n",
    "inaccurate_surety = []\n",
    "def validate(af, wes,label_counts):\n",
    "    classifications = {'low':0, 'high':0}\n",
    "    correct_preds = 0\n",
    "    all_preds = 0\n",
    "    for d_item in af:\n",
    "        my_dict = d_item['dictionary']\n",
    "        my_label = d_item['label']\n",
    "        [classification, score] = classify(my_dict, wes,label_counts)\n",
    "        classifications[classification] = classifications[classification] + 1\n",
    "        if classification == my_label:\n",
    "            correct_preds = correct_preds + 1\n",
    "        all_preds = all_preds + 1\n",
    "    print(classifications)\n",
    "    return float(correct_preds)/float(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'low': 0, 'high': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = all_features[4]['dictionary']\n",
    "\n",
    "validate([{'dictionary': dictionary, 'label': 'high'}], wes,label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Piper/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'low': 51, 'high': 0}\n",
      "0.49019607843137253\n",
      "{'low': 51, 'high': 0}\n",
      "0.5686274509803921\n",
      "{'low': 50, 'high': 1}\n",
      "0.5294117647058824\n",
      "{'low': 51, 'high': 0}\n",
      "0.5882352941176471\n",
      "{'low': 51, 'high': 0}\n",
      "0.5686274509803921\n",
      "{'low': 51, 'high': 0}\n",
      "0.5490196078431373\n",
      "{'low': 51, 'high': 0}\n",
      "0.5294117647058824\n",
      "{'low': 51, 'high': 0}\n",
      "0.6078431372549019\n",
      "{'low': 51, 'high': 0}\n",
      "0.5882352941176471\n",
      "{'low': 51, 'high': 0}\n",
      "0.6862745098039216\n"
     ]
    }
   ],
   "source": [
    "def find_acc(data,wes,label_counts):\n",
    "    for i in range(10):\n",
    "        shuffle(all_features)\n",
    "        wes = train_word_embeddings(all_features[0:n_train])\n",
    "        print(validate(all_features[n_train:n_total], wes, label_counts))\n",
    "        \n",
    "find_acc(all_features, wes, label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
